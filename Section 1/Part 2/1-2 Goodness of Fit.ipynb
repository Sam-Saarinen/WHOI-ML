{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model, Loss Function, and Optimization\n",
    "How do we know if a given regression is good or not? From a scientific standpoint, we should probably evaluate two factors: does it explain the data we've already seen; and does it accurately predict new data? Let's focus on the first one to start.\n",
    "\n",
    "There are lots of different ways to measure the accuracy of a regression. One way is just: are the predictions exactly right or not? But for any real dataset, none of the predictions will be exactly right, due to unexplained or unmodeled factors, random events, or simple measurement error. In that case, maybe we should try to measure how far each prediction is from the true value.\n",
    "\n",
    "In the case where there is only one measurement, this seems easy enough - predictions that are further away from the true value are worse. But once there are multiple predictions being evaluated, we have to decide how we trade off the errors in different predictions. Are errors of (1, -3, 5) better or worse than errors of (-3, -3, -3)?\n",
    "\n",
    "Suppose that the predictions are a vector $\\hat Y=<\\hat y_1, ..., \\hat y_n>$ and the true values are a vector $Y = <y_1, ..., y_n>$. There are various ways of defining the distance between $\\hat Y$ and $Y$. One of the most common is the Euclidean distance:\n",
    "\n",
    "$$E = \\sqrt{\\sum_{i = 1}^n (\\hat y_i - y_i)^2} $$\n",
    "\n",
    "This is a very natural distance measure, and corresponds to the geometric distance between the $\\hat Y$ and $Y$ vectors in n-dimensional Euclidean space. Because this measure produces stronger penalties for highly uneven errors (e.g. one really large error and many small errors), it tends to be sensitive to outliers, which could be either a strength or a weakness, depending on the data in question.\n",
    "\n",
    "Another natural distance function is called the _Manhattan Distance_, which sums the distance along each dimension (since in Manhattan, distances are based on walking the perimeters of blocks).\n",
    "\n",
    "$$ M = \\sum_{i = 1}^n \\left|\\hat y_i - y_i\\right| $$\n",
    "\n",
    "These error measures can be generalized to a family of distances called the $L_p$ norms:\n",
    "\n",
    "$$ L_p = \\left(\\sum_{i = 1}^n \\left|\\hat y_i - y_i\\right|^p \\right)^\\frac{1}{p} $$\n",
    "\n",
    "These error measures can be used as what we call a _loss function_. A good model is one that produces a small loss. It is unsurprising, then, that many machine learning algorithms have been designed to explicitly minimize some loss function. This introduces a general \"formula\" for machine learning that we'll see in many different contexts.\n",
    "\n",
    "$$ \\text{model class} + \\text{loss function} + \\text{optimization method} = \\text{machine learning algorithm}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Framework:\n",
    "def loss(true_vals, predictions):\n",
    "    pass # Implement to this interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment:\n",
    "1. Perform a fit on data using a linear model and a quadratic model.\n",
    "2. Measure the Euclidean distance (mean squared error) of each model on the dataset.\n",
    "3. Try to guess a function that explains the data better. Measure its performance.\n",
    "\n",
    "\n",
    "# Stretch Goals:\n",
    "- Try a different loss function (such as a different $L_p$ norm). Answer: Does the order of models change in terms of performance?\n",
    "- Try other regression methods from scikit-learn. Measure their performance. Which is the best?\n",
    "- Answer: What would you expect the $L_0$ and $L_\\infty$ norms to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
