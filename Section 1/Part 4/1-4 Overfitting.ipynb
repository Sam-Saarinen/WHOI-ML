{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation and Extrapolation errors\n",
    "Errors can vary over the domain of the model. Inputs outside the convex hull of observed points (or substantially far from any observed point) generally experience extrapolative error, which can be much more significant, but also harder to measure than interpolative error. In general, the validated error measures we consider here are all measure interpolation error. When the data frontier is easily identified (newest points in temporal data, for example), extrapolative error can be loosely empirically estimated using back-testing.\n",
    "\n",
    "# Train and Test Sets\n",
    "\n",
    "# Train, Test, and Validation Sets\n",
    "Sometimes we use test information to inform the way a model is designed. For example we may stop training or limit the capacity (number of models in an ensemble, for example) based on the test performance.\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "\n",
    "[Link to sklearn documentation](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Training Points 30\n",
      "Train Loss:  19.61604639942034\n",
      "Test Loss:  53.787083695185814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RankWarning: Polyfit may be poorly conditioned\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "input_data = np.arange(40)\n",
    "output_data = input_data*1.2 + .3 + np.random.normal(0, 7, len(input_data))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, output_data)\n",
    "print(\"Num Training Points\", len(X_train))\n",
    "\n",
    "model = np.poly1d(np.polyfit(X_train, y_train, len(X_train)))\n",
    "predictions_train = model(X_train)\n",
    "print(\"Train Loss: \", mean_squared_error(predictions_train, y_train))\n",
    "predictions_test = model(X_test)\n",
    "print(\"Test Loss: \", mean_squared_error(predictions_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment:\n",
    "1. Separate Training Data into Test and Train Sets. Plot performance vs. Number of points on train and test sets for a regression method of your choice.\n",
    "\n",
    "# Stretch Goals:\n",
    "- Design a cross-validation procedure to split the training data into n groups, and train on all of the groups except one, and then test the performance on the remaining subset.\n",
    "- Compute confidences on the measured test performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
